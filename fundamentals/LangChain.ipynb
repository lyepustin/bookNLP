{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "359697d5",
   "metadata": {},
   "source": [
    "# LangChain Fundamentals 游닄游닄"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4b7125",
   "metadata": {},
   "source": [
    "*This cookbook is derived from the [LangChain Conceptual Documentation](https://docs.langchain.com/docs/).*\n",
    "\n",
    "### **What is LangChain?**\n",
    "> LangChain is a framework designed for creating applications enhanced by language models.\n",
    "\n",
    "**In Brief**: LangChain simplifies the intricate aspects of working with and building AI models. It accomplishes this in two key ways:\n",
    "\n",
    "1. **Integration** - It enables the incorporation of external data, including files, other applications, and API data, into your Language Models (LMs).\n",
    "\n",
    "2. **Agency** - LangChain empowers your LMs to interact with their environment through decision-making, allowing them to determine the next course of action.\n",
    "\n",
    "### **Why Choose LangChain?**\n",
    "1. **Modularity** - LangChain facilitates the effortless interchange of abstractions and components essential for working with language models.\n",
    "\n",
    "2. **Tailored Sequences** - LangChain comes equipped with built-in support for utilizing and customizing 'chains,' which are sequences of actions strung together.\n",
    "\n",
    "3. **Rapid Deployment 游뚹** - Our team delivers updates at an exceptional speed, ensuring you stay current with the latest LM features.\n",
    "\n",
    "4. **Community Support 游논** - Join our vibrant Discord community for assistance, meetups, hackathons, and more.\n",
    "\n",
    "While LMs can initially appear straightforward (input text, output text), LangChain becomes indispensable as your applications become more complex.\n",
    "\n",
    "*Please note that this cookbook does not encompass all facets of LangChain. It has been carefully curated to expedite your journey to building and making an impact. For further details, please refer to the [LangChain Conceptual Documentation](https://docs.langchain.com/docs/).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9815081",
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "openai_api_key=os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bb564d",
   "metadata": {},
   "source": [
    "# LangChain Components\n",
    "\n",
    "## Schema - The Fundamental Framework for Engaging with LLMs\n",
    "\n",
    "### **The language-driven approach for engaging with Language Models (LMs)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e462b5d",
   "metadata": {},
   "source": [
    "## Models - The interface to the AI brains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27fe982",
   "metadata": {},
   "source": [
    "### **Language Model**\n",
    "A model designed for transforming text input into text output!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74b1a72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(model_name=\"text-ada-001\", openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6399c295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nParis'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(\"What's the capital of France?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f39eb39",
   "metadata": {},
   "source": [
    "### **Chat Messages**\n",
    "Similar to text, but categorized by message type (System, Human, AI)\n",
    "\n",
    "* **System** - Provides essential contextual information to guide the AI's actions.\n",
    "* **Human** - Messages intended to represent user input.\n",
    "* **AI** - Messages showcasing the AI's responses.\n",
    "* **Temperature** - A parameter that influences the randomness and creativity of the AI's responses (0.2 low, 0.8 high).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "99b0935b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "chat = ChatOpenAI(temperature=.8, openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70095b16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Of course! Here are a few original and fresh proposal ideas for your trip to Rome:\\n\\n1. \"Roman Treasure Hunt\": Plan a treasure hunt around the city, leading her to meaningful spots in Rome that hold significance for both of you. At the final destination, surprise her with the proposal.\\n\\n2. \"Private Terrace Dinner\": Arrange a private dinner on a beautiful terrace overlooking the iconic landmarks of Rome. As the sun sets and the city lights up, express your love and propose to her under the romantic ambiance.\\n\\n3. \"Love Lock Bridge\": Take her to Ponte Milvio, a famous bridge where couples attach love locks. Secretly bring your own personalized lock and key. As you attach it together, tell her it symbolizes your commitment and surprise her with the proposal.\\n\\n4. \"Hidden Ring in Gelato\": Plan a gelato tasting tour around Rome. Coordinate with a gelato shop in advance to hide the engagement ring in one of the flavors. When she finds it, get down on one knee and propose.\\n\\n5. \"Scenic Hot Air Balloon Ride\": Arrange a hot air balloon ride over the beautiful countryside near Rome. As you soar above the breathtaking landscape, surprise her with the proposal against the backdrop of the stunning views.\\n\\nRemember, personal touches and thoughtfulness go a long way. Choose an idea that aligns with your girlfriend\\'s preferences and create a moment that reflects your unique relationship. Good luck with your proposal!', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(\n",
    "    [\n",
    "        SystemMessage(content=\"You're a helpful AI wedding preparation assistant, providing concise advice to users\"),\n",
    "        HumanMessage(content=\"I want to propose to my girlfriend. Soon we will have a trip to Rome. I would like to do it in an original, fresh way and surprise her with it. Can you help me with some ideas?\")\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a425aaa",
   "metadata": {},
   "source": [
    "You can also provide additional chat history along with the AI's responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fd3fe88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Here are a few more ideas for a beach wedding:\\n\\n1. Use driftwood or bamboo to create an archway or altar for the ceremony.\\n2. Opt for a sandy aisle runner or scatter seashells along the path.\\n3. Decorate with tropical flowers like orchids, hibiscus, or bird of paradise.\\n4. Incorporate nautical elements such as ropes, anchors, or sailor's knots into your decor.\\n5. Offer flip-flops or sandals for guests to wear instead of formal shoes.\\n6. Set up a beach lounge area with comfortable seating and beach umbrellas for guests to relax.\\n7. Utilize lanterns or string lights to create a magical ambiance for an evening beach wedding.\\n8. Serve tropical cocktails or have a beach-themed signature drink.\\n9. Consider having a beach bonfire or fireworks display to end the night with a bang.\\n10. Provide sunscreen, insect repellent, and fans to keep guests comfortable in the outdoor setting.\\n\\nRemember, simplicity and natural elements are key for a beach wedding.\", additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(\n",
    "    [\n",
    "        SystemMessage(content=\"You're a helpful AI wedding preparation assistant, providing concise advice to users\"),\n",
    "        HumanMessage(content=\"I'm planning my wedding. Any suggestions for beach-themed decorations\"),\n",
    "        AIMessage(content=\"For a beach-themed wedding, consider seashell centerpieces and aqua-blue accents\"),\n",
    "        HumanMessage(content=\"What other ideas do you have for a beach wedding?\")\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b70f23",
   "metadata": {},
   "source": [
    "### **Text Embedding Model**\n",
    "Convert your text into a vector, represented as a series of numbers encoding the semantic 'meaning' of your text. Primarily employed for text-to-text comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1655de82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2c85e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Hello, I'm enjoying a nice day\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ddc5a368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your embedding is length 1536\n",
      "Here's a sample: [-0.010706691071391106, 0.016259444877505302, -0.0029711835086345673, -0.04140329733490944, 0.0067553394474089146]...\n"
     ]
    }
   ],
   "source": [
    "text_embedding = embeddings.embed_query(text)\n",
    "print (f\"Your embedding is length {len(text_embedding)}\")\n",
    "print (f\"Here's a sample: {text_embedding[:5]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38fe99f",
   "metadata": {},
   "source": [
    "## Prompts - Text Commonly Employed as Instructions to Your Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9318ed",
   "metadata": {},
   "source": [
    "### **Prompt**\n",
    "The input provided to the underlying model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d270239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nIt reminds me of a beautiful summer day, where I can spend time outdoors with friends and family, enjoying the warmth and the beauty of nature.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(model_name=\"text-davinci-003\", openai_api_key=openai_api_key)\n",
    "\n",
    "prompt = \"\"\"\n",
    "The sun is shining brightly outside.\n",
    "\n",
    "What does that remind you of?\n",
    "\"\"\"\n",
    "\n",
    "llm(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74988254",
   "metadata": {},
   "source": [
    "### **Prompt Template**\n",
    "A tool that facilitates the generation of prompts by combining user input, dynamic data, and a predefined template string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abcc212d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Prompt: \n",
      "I really want to support the Manchester United. What should I do as a fan?\n",
      "\n",
      "Respond in one short sentence\n",
      "\n",
      "-----------\n",
      "LLM Output: Cheer for the team at matches and show your support online.\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "llm = OpenAI(model_name=\"text-davinci-003\", openai_api_key=openai_api_key)\n",
    "\n",
    "template = \"\"\"\n",
    "I really want to support the {team}. What should I do as a fan?\n",
    "\n",
    "Respond in one short sentence\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"team\"],\n",
    "    template=template,\n",
    ")\n",
    "\n",
    "final_prompt = prompt.format(team='Manchester United')\n",
    "\n",
    "print(f\"Final Prompt: {final_prompt}\")\n",
    "print(\"-----------\")\n",
    "print(f\"LLM Output: {llm(final_prompt)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed40bac2",
   "metadata": {},
   "source": [
    "### **Example Selectors**\n",
    "An easy way to select from a series of examples that allow you to dynamic place in-context information into your prompt. Often used when your task is nuanced or you have a large list of examples.\n",
    "\n",
    "Check out different types of example selectors [here](https://python.langchain.com/docs/modules/model_io/prompts/example_selectors/)\n",
    "\n",
    "If you want an overview on why examples are important (prompt engineering), check out [this video](https://www.youtube.com/watch?v=dOxUroR57xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aaf36cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.example_selector import SemanticSimilarityExampleSelector\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(model_name=\"text-davinci-003\", openai_api_key=openai_api_key)\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\", \"output\"],\n",
    "    template=\"Example Input: {input}\\nExample Output: {output}\",\n",
    ")\n",
    "\n",
    "examples = [\n",
    "    {\"input\": \"pirate\", \"output\": \"ship\"},\n",
    "    {\"input\": \"pilot\", \"output\": \"plane\"},\n",
    "    {\"input\": \"driver\", \"output\": \"car\"},\n",
    "    {\"input\": \"tree\", \"output\": \"ground\"},\n",
    "    {\"input\": \"bird\", \"output\": \"nest\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12b4798b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Could not import faiss python package. Please install it with `pip install faiss-gpu` (for CUDA supported GPU) or `pip install faiss-cpu` (depending on Python version).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\pusha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\vectorstores\\faiss.py:47\u001b[0m, in \u001b[0;36mdependable_faiss_import\u001b[1;34m(no_avx2)\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 47\u001b[0m         \u001b[39mimport\u001b[39;00m \u001b[39mfaiss\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'faiss'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32md:\\Data\\Develop\\bookNLP\\fundamentals\\LangChain.ipynb Cell 25\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Data/Develop/bookNLP/fundamentals/LangChain.ipynb#X33sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m example_selector \u001b[39m=\u001b[39m SemanticSimilarityExampleSelector\u001b[39m.\u001b[39;49mfrom_examples(\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Data/Develop/bookNLP/fundamentals/LangChain.ipynb#X33sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     examples, \n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Data/Develop/bookNLP/fundamentals/LangChain.ipynb#X33sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     OpenAIEmbeddings(openai_api_key\u001b[39m=\u001b[39;49mopenai_api_key), \n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Data/Develop/bookNLP/fundamentals/LangChain.ipynb#X33sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39m# VectorStore \u001b[39;49;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Data/Develop/bookNLP/fundamentals/LangChain.ipynb#X33sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     FAISS, \n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Data/Develop/bookNLP/fundamentals/LangChain.ipynb#X33sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39m# This is the number of examples to produce.\u001b[39;49;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Data/Develop/bookNLP/fundamentals/LangChain.ipynb#X33sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     k\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Data/Develop/bookNLP/fundamentals/LangChain.ipynb#X33sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\pusha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\prompts\\example_selector\\semantic_similarity.py:95\u001b[0m, in \u001b[0;36mSemanticSimilarityExampleSelector.from_examples\u001b[1;34m(cls, examples, embeddings, vectorstore_cls, k, input_keys, **vectorstore_cls_kwargs)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     94\u001b[0m     string_examples \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(sorted_values(eg)) \u001b[39mfor\u001b[39;00m eg \u001b[39min\u001b[39;00m examples]\n\u001b[1;32m---> 95\u001b[0m vectorstore \u001b[39m=\u001b[39m vectorstore_cls\u001b[39m.\u001b[39;49mfrom_texts(\n\u001b[0;32m     96\u001b[0m     string_examples, embeddings, metadatas\u001b[39m=\u001b[39;49mexamples, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mvectorstore_cls_kwargs\n\u001b[0;32m     97\u001b[0m )\n\u001b[0;32m     98\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m(vectorstore\u001b[39m=\u001b[39mvectorstore, k\u001b[39m=\u001b[39mk, input_keys\u001b[39m=\u001b[39minput_keys)\n",
      "File \u001b[1;32mc:\\Users\\pusha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\vectorstores\\faiss.py:603\u001b[0m, in \u001b[0;36mFAISS.from_texts\u001b[1;34m(cls, texts, embedding, metadatas, ids, **kwargs)\u001b[0m\n\u001b[0;32m    584\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Construct FAISS wrapper from raw documents.\u001b[39;00m\n\u001b[0;32m    585\u001b[0m \n\u001b[0;32m    586\u001b[0m \u001b[39mThis is a user friendly interface that:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    600\u001b[0m \u001b[39m        faiss = FAISS.from_texts(texts, embeddings)\u001b[39;00m\n\u001b[0;32m    601\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    602\u001b[0m embeddings \u001b[39m=\u001b[39m embedding\u001b[39m.\u001b[39membed_documents(texts)\n\u001b[1;32m--> 603\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m__from(\n\u001b[0;32m    604\u001b[0m     texts,\n\u001b[0;32m    605\u001b[0m     embeddings,\n\u001b[0;32m    606\u001b[0m     embedding,\n\u001b[0;32m    607\u001b[0m     metadatas\u001b[39m=\u001b[39;49mmetadatas,\n\u001b[0;32m    608\u001b[0m     ids\u001b[39m=\u001b[39;49mids,\n\u001b[0;32m    609\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m    610\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\pusha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\vectorstores\\faiss.py:557\u001b[0m, in \u001b[0;36mFAISS.__from\u001b[1;34m(cls, texts, embeddings, embedding, metadatas, ids, normalize_L2, distance_strategy, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    546\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__from\u001b[39m(\n\u001b[0;32m    547\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    555\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[0;32m    556\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m FAISS:\n\u001b[1;32m--> 557\u001b[0m     faiss \u001b[39m=\u001b[39m dependable_faiss_import()\n\u001b[0;32m    558\u001b[0m     \u001b[39mif\u001b[39;00m distance_strategy \u001b[39m==\u001b[39m DistanceStrategy\u001b[39m.\u001b[39mMAX_INNER_PRODUCT:\n\u001b[0;32m    559\u001b[0m         index \u001b[39m=\u001b[39m faiss\u001b[39m.\u001b[39mIndexFlatIP(\u001b[39mlen\u001b[39m(embeddings[\u001b[39m0\u001b[39m]))\n",
      "File \u001b[1;32mc:\\Users\\pusha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\vectorstores\\faiss.py:49\u001b[0m, in \u001b[0;36mdependable_faiss_import\u001b[1;34m(no_avx2)\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[39mimport\u001b[39;00m \u001b[39mfaiss\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[1;32m---> 49\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[0;32m     50\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCould not import faiss python package. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     51\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease install it with `pip install faiss-gpu` (for CUDA supported GPU) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     52\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mor `pip install faiss-cpu` (depending on Python version).\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     53\u001b[0m     )\n\u001b[0;32m     54\u001b[0m \u001b[39mreturn\u001b[39;00m faiss\n",
      "\u001b[1;31mImportError\u001b[0m: Could not import faiss python package. Please install it with `pip install faiss-gpu` (for CUDA supported GPU) or `pip install faiss-cpu` (depending on Python version)."
     ]
    }
   ],
   "source": [
    "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
    "    examples, \n",
    "    OpenAIEmbeddings(openai_api_key=openai_api_key), \n",
    "    # VectorStore \n",
    "    FAISS, \n",
    "    # This is the number of examples to produce.\n",
    "    k=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf30107",
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_prompt = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"Give the location an item is usually found in\",\n",
    "    suffix=\"Input: {noun}\\nOutput:\",\n",
    "    input_variables=[\"noun\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369442bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give the location an item is usually found in\n",
      "\n",
      "Example Input: driver\n",
      "Example Output: car\n",
      "\n",
      "Example Input: pilot\n",
      "Example Output: plane\n",
      "\n",
      "Input: student\n",
      "Output:\n"
     ]
    }
   ],
   "source": [
    "my_noun = \"student\"\n",
    "print(similar_prompt.format(noun=my_noun))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb910f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' classroom'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(similar_prompt.format(noun=my_noun))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8474c91d",
   "metadata": {},
   "source": [
    "### **Output Parsers**\n",
    "A helpful way to format the output of a model. Usually used for structured output.\n",
    "\n",
    "Two big concepts:\n",
    "\n",
    "**1. Format Instructions** - A autogenerated prompt that tells the LLM how to format it's response based off your desired result\n",
    "\n",
    "**2. Parser** - A method which will extract your model's text output into a desired structure (usually json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58353756",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee36f881",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model_name=\"text-davinci-003\", openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa59be3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_schemas = [\n",
    "    ResponseSchema(name=\"bad_string\", description=\"This a poorly formatted user input string\"),\n",
    "    ResponseSchema(name=\"good_string\", description=\"This is your response, a reformatted response\")\n",
    "]\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1079f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"bad_string\": string  // This a poorly formatted user input string\n",
      "\t\"good_string\": string  // This is your response, a reformatted response\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# See the prompt template you created for formatting\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "print (format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9aaae5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You will be given a poorly formatted string from a user.\n",
      "Reformat it and make sure all the words are spelled correctly\n",
      "\n",
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"bad_string\": string  // This a poorly formatted user input string\n",
      "\t\"good_string\": string  // This is your response, a reformatted response\n",
      "}\n",
      "```\n",
      "\n",
      "% USER INPUT:\n",
      "welcom to califonya!\n",
      "\n",
      "YOUR RESPONSE:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "You will be given a poorly formatted string from a user.\n",
    "Reformat it and make sure all the words are spelled correctly\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "% USER INPUT:\n",
    "{user_input}\n",
    "\n",
    "YOUR RESPONSE:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"user_input\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions},\n",
    "    template=template\n",
    ")\n",
    "\n",
    "promptValue = prompt.format(user_input=\"welcom to califonya!\")\n",
    "\n",
    "print(promptValue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b116bb23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'```json\\n{\\n\\t\"bad_string\": \"welcom to califonya!\",\\n\\t\"good_string\": \"Welcome to California!\"\\n}\\n```'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_output = llm(promptValue)\n",
    "llm_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "985aa814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bad_string': 'welcom to califonya!', 'good_string': 'Welcome to California!'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_parser.parse(llm_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b43cec2",
   "metadata": {},
   "source": [
    "## Indexes - Structuring documents to LLMs can work with them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bf9634",
   "metadata": {},
   "source": [
    "### **Documents**\n",
    "A object containing both text content and associated metadata, offering supplementary information about the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3bbf58b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "150e8759",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='This is a sample document containing various text excerpts collected from different sources.', metadata={'document_id': 987654, 'document_source': 'Research Journals', 'document_create_time': 1680013019})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Document(page_content=\"This is a sample document containing various text extracts collected from different sources.\",\n",
    "         metadata={\n",
    "             'document_id' : 987654,\n",
    "             'document_source' : \"Research Journals\",\n",
    "             'document_create_time' : 1680013019\n",
    "         })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f904e9",
   "metadata": {},
   "source": [
    "### **Internet Loaders**\n",
    "Effortless methods for bringing data in from external sources, with shared functionality in alignment with [OpenAI Plugins](https://openai.com/blog/chatgpt-plugins), especially those related to retrieval plugins as highlighted [here](https://github.com/openai/chatgpt-retrieval-plugin).\n",
    "\n",
    "Explore an extensive collection of document loaders within this [comprehensive list](https://python.langchain.com/en/latest/modules/indexes/document_loaders.html). Additionally, you can find a plethora of options on the [Llama Index](https://llamahub.ai/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ba88e05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WebBaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ee693520",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = WebBaseLoader(\"https://api.chucknorris.io/jokes/random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "88d89ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e814f930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 comments\n",
      "Here's a sample:\n",
      "\n",
      "{\"categories\":[],\"created_at\":\"2020-01-05 13:42:28.420821\",\"icon_url\":\"https://assets.chucknorris.host/img/avatar/chuck-norris.png\",\"id\":\"iqSTt3dnQgqP\n"
     ]
    }
   ],
   "source": [
    "print (f\"Found {len(data)} comments\")\n",
    "print (f\"Here's a sample:\\n\\n{''.join([x.page_content[:150] for x in data[:2]])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9601db",
   "metadata": {},
   "source": [
    "### **Text Splitters**\n",
    "When dealing with extensive documents, such as books, that exceed the LLM's capacity, you may need to divide them into manageable chunks. Text splitters come to the rescue in such situations.\n",
    "\n",
    "You have the flexibility to choose from various methods to segment your text into chunks, allowing you to experiment with [different options](https://python.langchain.com/en/latest/modules/indexes/text_splitters.html) to determine the most suitable approach for your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "95713e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a54455f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 1 document\n"
     ]
    }
   ],
   "source": [
    "with open(f\"{os.getcwd()}\\\\..\\\\data\\\\quijote.txt\", encoding=\"utf-8\") as f:\n",
    "    pg_work = f.read()\n",
    "    \n",
    "print (f\"You have {len([pg_work])} document\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d19acb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=int(os.getenv(\"TEXT_SPLITTER_CHUNK_SIZE\")),\n",
    "    chunk_overlap=int(os.getenv(\"TEXT_SPLITTER_CHUNK_OVERLAP\")),\n",
    "    length_function=len\n",
    ")\n",
    "\n",
    "texts = text_splitter.create_documents([pg_work])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e3090f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 2863 documents\n"
     ]
    }
   ],
   "source": [
    "print (f\"You have {len(texts)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "87a0f45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preview:\n",
      "DON QUIJOTE DE LA MANCHA\n",
      "Miguel de Cervantes Saavedra \n",
      "\n",
      "PRIMERA PARTE\n",
      "CAPI패TULO 1: Que trata de la condicio패n y ejercicio del famoso hidalgo D. Quijote de la Mancha\n"
     ]
    }
   ],
   "source": [
    "print (\"Preview:\")\n",
    "print (texts[0].page_content, \"\\n\")\n",
    "print (texts[1].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f85defb",
   "metadata": {},
   "source": [
    "### **Retrievers**\n",
    "Simplified means to integrate documents with language models seamlessly.\n",
    "\n",
    "Retrievers encompass a diverse range of functionalities, with the most commonly used one being the VectoreStoreRetriever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cccbd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "loader = TextLoader(f\"{os.getcwd()}\\\\..\\\\data\\\\quijote.txt\", encoding=\"utf-8\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dab1c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "db = FAISS.from_documents(texts, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e62372be",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3846a3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = retriever.get_relevant_documents(\"how did quixote feel about being knighted?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db383cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nunca fuera caballero de damas tan bien servido, como fuera D. Quijote cuando de su aldea vino; doncellas curaban de패l, princesas de su Rocino.\n",
      "\n",
      "brevedad que pudiese; porque si fuese otra vez acometido, y se viese armado caballero, no pensaba dejar persona viva en el castillo, excepto aquellas que e패l le mandase, a quien por su respeto dejari패\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n\".join([x.page_content[:200] for x in docs[:2]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24193139",
   "metadata": {},
   "source": [
    "### **VectorStores**\n",
    "VectorStores are specialized databases designed for storing vectors, often used in various applications like similarity search and recommendation systems. Some of the most popular VectorStores include [Pinecone](https://www.pinecone.io/), [Weaviate](https://weaviate.io/) or [Qdrant](https://qdrant.io/). You can find more examples and information on VectorStores in OpenAI's [retriever documentation](https://github.com/openai/chatgpt-retrieval-plugin#choosing-a-vector-database). Additionally, [Chroma](https://www.trychroma.com/) and [FAISS](https://engineering.fb.com/2017/03/29/data-infrastructure/faiss-a-library-for-efficient-similarity-search/) are user-friendly options for local vector storage and retrieval.\n",
    "\n",
    "Conceptually, think of VectorStores as tables with two main columns:\n",
    "\n",
    "Example:\n",
    "\n",
    "| Embedding      | Metadata |\n",
    "| ----------- | ----------- |\n",
    "| [-0.0001564, -0.0031651, ...]      | {'date': '1/2/23'}       |\n",
    "| [-0.0003547, 1.4654132, ...]   | {'date': '1/3/23'}        |\n",
    "\n",
    "In the table, the \"Embedding\" column stores vectors, often representing data points, while the \"Metadata\" column contains associated metadata, which can include information such as timestamps, labels, or any other relevant data for each vector. These VectorStores enable efficient storage, retrieval, and querying of vector-based information in various applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c5533ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "loader = TextLoader(f\"{os.getcwd()}\\\\..\\\\data\\\\quijote.txt\", encoding=\"utf-8\")\n",
    "documents = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "661fdf19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 184 documents\n"
     ]
    }
   ],
   "source": [
    "print (f\"You have {len(texts)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e99ac0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_list = embeddings.embed_documents([text.page_content for text in texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89e7758c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 184 embeddings\n",
      "Here's a sample of one: [-0.008079922610350081, -0.013808179394331007, 0.00409026436481697]...\n"
     ]
    }
   ],
   "source": [
    "print (f\"You have {len(embedding_list)} embeddings\")\n",
    "print (f\"Here's a sample of one: {embedding_list[0][:3]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b9b79b",
   "metadata": {},
   "source": [
    "## Memory\n",
    "Helping LLMs remember information.\n",
    "\n",
    "Memory is a bit of a loose term. It could be as simple as remembering information you've chatted about in the past or more complicated information retrieval.\n",
    "\n",
    "We'll keep it towards the Chat Message use case. This would be used for chat bots.\n",
    "\n",
    "There are many types of memory, explore [the documentation](https://python.langchain.com/en/latest/modules/memory/how_to_guides.html) to see which one fits your use case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43b49da",
   "metadata": {},
   "source": [
    "### Chat Message History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "893a18c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(temperature=0, openai_api_key=openai_api_key)\n",
    "\n",
    "history = ChatMessageHistory()\n",
    "\n",
    "history.add_ai_message(\"hi!\")\n",
    "\n",
    "history.add_user_message(\"what is the capital of france?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a2949fda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='hi!', additional_kwargs={}, example=False),\n",
       " HumanMessage(content='what is the capital of france?', additional_kwargs={}, example=False)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9b74d5cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of France is Paris.', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_response = chat(history.messages)\n",
    "ai_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "529e168f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='hi!', additional_kwargs={}, example=False),\n",
       " HumanMessage(content='what is the capital of france?', additional_kwargs={}, example=False),\n",
       " AIMessage(content='The capital of France is Paris.', additional_kwargs={}, example=False)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.add_ai_message(ai_response.content)\n",
    "history.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29fc79c",
   "metadata": {},
   "source": [
    "## Chains 久勇久勇久勇끂n",
    "Combining different LLM calls and action automatically\n",
    "\n",
    "Ex: Summary #1, Summary #2, Summary #3 > Final Summary\n",
    "\n",
    "Check out [this video](https://www.youtube.com/watch?v=f9_BWhCI4Zo&t=2s) explaining different summarization chain types\n",
    "\n",
    "There are [many applications of chains](https://python.langchain.com/en/latest/modules/chains/how_to_guides.html) search to see which are best for your use case.\n",
    "\n",
    "We'll cover two of them:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34ba415",
   "metadata": {},
   "source": [
    "### 1. Simple Sequential Chains\n",
    "\n",
    "Easy chains where you can use the output of an LLM as an input into another. Good for breaking up tasks (and keeping your LLM focused)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79fc0950",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "llm = OpenAI(temperature=1, openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43d4494a",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Your job is to come up with a classic dish from the area that the users suggests.\n",
    "% USER LOCATION\n",
    "{user_location}\n",
    "\n",
    "YOUR RESPONSE:\n",
    "\"\"\"\n",
    "prompt_template = PromptTemplate(input_variables=[\"user_location\"], template=template)\n",
    "\n",
    "# Holds my 'location' chain\n",
    "location_chain = LLMChain(llm=llm, prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6c8e00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Given a meal, give a short and simple recipe on how to make that dish at home.\n",
    "% MEAL\n",
    "{user_meal}\n",
    "\n",
    "YOUR RESPONSE:\n",
    "\"\"\"\n",
    "prompt_template = PromptTemplate(input_variables=[\"user_meal\"], template=template)\n",
    "\n",
    "# Holds my 'meal' chain\n",
    "meal_chain = LLMChain(llm=llm, prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "40f6ece8",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Given a recipe on how to cook a dish, estimates the time spent on each task.\n",
    "% MEAL\n",
    "{recipe}\n",
    "\n",
    "YOUR RESPONSE:\n",
    "\"\"\"\n",
    "prompt_template = PromptTemplate(input_variables=[\"recipe\"], template=template)\n",
    "\n",
    "# Holds my 'meal' chain\n",
    "estimate_chain = LLMChain(llm=llm, prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e0b83f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_chain = SimpleSequentialChain(chains=[location_chain, meal_chain, estimate_chain], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d19c64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mA classic dish from Orihuela is Arroz a Banda, which is a saffron paella that is cooked with monkfish, squid, and shrimp.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mIngredients:\n",
      "- 2 cloves of garlic\n",
      "- 2 tablespoons of olive oil\n",
      "- 1 cup of short-grain rice\n",
      "- 4 cups of fish or vegetable broth\n",
      "- 1 small pinch of saffron\n",
      "- 8 ounces of monkfish, squid, and shrimp\n",
      "- 1/2 teaspoon of smoked paprika\n",
      "- Salt, to taste\n",
      "\n",
      "Instructions:\n",
      "1. Heat olive oil in a pot over medium-high heat.\n",
      "2. Add garlic and cook until fragrant, about 1 minute.\n",
      "3. Stir in rice and toast for a few minutes, until lightly browned.\n",
      "4. Add broth, saffron, and paprika and stir to combine.\n",
      "5. Bring the mixture to a boil, then reduce the heat to low and cover with a lid.\n",
      "6. Simmer for 15 minutes, stirring occasionally.\n",
      "7. Add the monkfish, squid, and shrimp and cook for an additional 5 minutes.\n",
      "8. Season with salt and serve.\u001b[0m\n",
      "\u001b[38;5;200m\u001b[1;3m- Heat olive oil in pot: 1 minute\n",
      "- Add garlic and cook until fragrant: 1 minute\n",
      "- Stir in rice and toast: 5 minutes\n",
      "- Add broth, saffron and paprika and stir to combine: 2 minutes\n",
      "- Bring mixture to a boil: 2 minutes\n",
      "- Reduce heat to low and cover with lid: 2 minutes\n",
      "- Simmer for 15 minutes, stirring occasionally: 15 minutes\n",
      "- Add monkfish, squid and shrimp, cook for an additional 5 minutes: 5 minutes\n",
      "- Season with salt and serve: 1 minute\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "review = overall_chain.run(\"Orihuela\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6191bf5",
   "metadata": {},
   "source": [
    "### 2. Summarization Chain\n",
    "\n",
    "Easily run through long numerous documents and get a summary. Check out [this video](https://www.youtube.com/watch?v=f9_BWhCI4Zo) for other chain types besides map-reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6f218c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MapReduceDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"January 2017Because biographies of famous scientists tend to \n",
      "edit out their mistakes, we underestimate the \n",
      "degree of risk they were willing to take.\n",
      "And because anything a famous scientist did that\n",
      "wasn't a mistake has probably now become the\n",
      "conventional wisdom, those choices don't\n",
      "seem risky either.Biographies of Newton, for example, understandably focus\n",
      "more on physics than alchemy or theology.\n",
      "The impression we get is that his unerring judgment\n",
      "led him straight to truths no one else had noticed.\n",
      "How to explain all the time he spent on alchemy\n",
      "and theology?  Well, smart people are often kind of\n",
      "crazy.But maybe there is a simpler explanation. Maybe\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"the smartness and the craziness were not as separate\n",
      "as we think. Physics seems to us a promising thing\n",
      "to work on, and alchemy and theology obvious wastes\n",
      "of time. But that's because we know how things\n",
      "turned out. In Newton's day the three problems \n",
      "seemed roughly equally promising. No one knew yet\n",
      "what the payoff would be for inventing what we\n",
      "now call physics; if they had, more people would \n",
      "have been working on it. And alchemy and theology\n",
      "were still then in the category Marc Andreessen would \n",
      "describe as \"huge, if true.\"Newton made three bets. One of them worked. But \n",
      "they were all risky.\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\" Biographies of famous scientists fail to show the risks they took and the mistakes they made, leading to an unbalanced impression. Explaining the detours taken in their exploration of topics such as alchemy and theology, smart people are often thought of as crazy; however, there may be a simpler explanation.\n",
      "\n",
      " In Newton's day, no one knew how successful inventing physics, alchemy, and theology would be. But Newton made the decision to pursue all three topics, and one of them was a success. Even though our current view is that physics is the superior venture and alchemy and theology are waste of time, Newton's risky decision shows that these things were once considered equally important.\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Biographies of famous scientists do not include the risks and mistakes taken when exploring unproven topics such as alchemy and theology, leading to an unbalanced view. Newton took a risk by exploring all three of these topics, and it paid off in success with physics. Despite the current view that alchemy and theology are a waste of time, Newton's decision shows that once they were regarded equally as important.\""
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = TextLoader('data/PaulGrahamEssays/disc.txt')\n",
    "documents = loader.load()\n",
    "\n",
    "# Get your splitter ready\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=700, chunk_overlap=50)\n",
    "\n",
    "# Split your docs into texts\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "# There is a lot of complexity hidden in this one line. I encourage you to check out the video above for more detail\n",
    "chain = load_summarize_chain(llm, chain_type=\"map_reduce\", verbose=True)\n",
    "chain.run(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f6193c",
   "metadata": {},
   "source": [
    "## Agents 游뱄游뱄\n",
    "\n",
    "Official LangChain Documentation describes agents perfectly (emphasis mine):\n",
    "> Some applications will require not just a predetermined chain of calls to LLMs/other tools, but potentially an **unknown chain** that depends on the user's input. In these types of chains, there is a 라gent which has access to a suite of tools. Depending on the user input, the agent can then **decide which, if any, of these tools to call**.\n",
    "\n",
    "\n",
    "Basically you use the LLM not just for text output, but also for decision making. The coolness and power of this functionality can't be overstated enough.\n",
    "\n",
    "Sam Altman emphasizes that the LLMs are good '[reasoning engine](https://www.youtube.com/watch?v=L_Guz73e6fw&t=867s)'. Agent take advantage of this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce05d51",
   "metadata": {},
   "source": [
    "### Agents\n",
    "\n",
    "The language model that drives decision making.\n",
    "\n",
    "More specifically, an agent takes in an input and returns a response corresponding to an action to take along with an action input. You can see different types of agents (which are better for different use cases) [here](https://python.langchain.com/en/latest/modules/agents/agent_types.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f696b65c",
   "metadata": {},
   "source": [
    "### Tools\n",
    "\n",
    "A 'capability' of an agent. This is an abstraction on top of a function that makes it easy for LLMs (and agents) to interact with it. Ex: Google search.\n",
    "\n",
    "This area shares commonalities with [OpenAI plugins](https://platform.openai.com/docs/plugins/introduction)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11f8231",
   "metadata": {},
   "source": [
    "### Toolkit\n",
    "\n",
    "Groups of tools that your agent can select from\n",
    "\n",
    "Let's bring them all together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "67d5d82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.llms import OpenAI\n",
    "import json\n",
    "\n",
    "llm = OpenAI(temperature=0, openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0ddcdbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "serpapi_api_key='...'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "44fad67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "toolkit = load_tools([\"serpapi\"], llm=llm, serpapi_api_key=serpapi_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f544a74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(toolkit, llm, agent=\"zero-shot-react-description\", verbose=True, return_intermediate_steps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c4882754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should try to find out what band Natalie Bergman is a part of.\n",
      "Action: Search\n",
      "Action Input: \"Natalie Bergman band\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mNatalie Bergman is an American singer-songwriter. She is one half of the duo Wild Belle, along with her brother Elliot Bergman. Her debut solo album, Mercy, was released on Third Man Records on May 7, 2021. She is based in Los Angeles.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should search for the debut album of Wild Belle.\n",
      "Action: Search\n",
      "Action Input: \"Wild Belle debut album\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mIsles\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: Isles is the debut album of Wild Belle, the band that Natalie Bergman is a part of.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response = agent({\"input\":\"what was the first album of the\" \n",
    "                    \"band that Natalie Bergman is a part of?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ba438064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  [\n",
      "    [\n",
      "      \"Search\",\n",
      "      \"Natalie Bergman band\",\n",
      "      \" I should try to find out what band Natalie Bergman is a part of.\\nAction: Search\\nAction Input: \\\"Natalie Bergman band\\\"\"\n",
      "    ],\n",
      "    \"Natalie Bergman is an American singer-songwriter. She is one half of the duo Wild Belle, along with her brother Elliot Bergman. Her debut solo album, Mercy, was released on Third Man Records on May 7, 2021. She is based in Los Angeles.\"\n",
      "  ],\n",
      "  [\n",
      "    [\n",
      "      \"Search\",\n",
      "      \"Wild Belle debut album\",\n",
      "      \" I should search for the debut album of Wild Belle.\\nAction: Search\\nAction Input: \\\"Wild Belle debut album\\\"\"\n",
      "    ],\n",
      "    \"Isles\"\n",
      "  ]\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(response[\"intermediate_steps\"], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9c30d2",
   "metadata": {},
   "source": [
    "![Wild Belle](data/WildBelle1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f4b368",
   "metadata": {},
   "source": [
    "游꿧Enjoy游꿧\n",
    "https://open.spotify.com/track/1eREJIBdqeCcqNCB1pbz7w?si=c014293b63c7478c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3193b53e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
